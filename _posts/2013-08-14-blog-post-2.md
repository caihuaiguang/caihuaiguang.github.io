---
title: 'Blog Post number 2'
date: 2020-02-09
permalink: /posts/2020/02/blog-post-2/
tags:
  - cool posts
  - category1
  - category2
---

[TOC]

# 人工智能笔记

# 概述



## 概念

### 信息

​	信息与物质及能量构成整个宇宙。

### 人的认识过程

​	**信息**经过**感觉**输入到**神经系统**，再经过**大脑思维**变为**认识**。

### 智能 = 知识集 + 智力

### 人工智能

​	Artificial Intelligence， 简称AI；

​	它是研究如何将人的智能**转化**为机器智能， 或者是用机器来**模拟或实现**人的智能。

## 人工智能的研究方法

### 符号主义（Symbolicism）学派

​	认为人工智能源于**数理逻辑**。该学派将数学严格公理化，从公理出发，由逻辑推理得到引理，定理，推论。 

### 联结主义（Connetionism）学派

​	认为人工智能源于**仿生学**。该学派的主要理论基础为神经网络及神经网络间的连接机制与学习算法。如果

### 行为主义（Actionism）学派

​	来源于**控制论**及 **“感知——动作”型控制系统**。该学派认为智能取决于**感知和行动**，人工智能可以像人类智能一样逐步进化，以及智能行为只能在现实世界中与周围环境交互作用而表现出来。

### 比较

​	符号主义是从宏观上模拟人的思维过程的话， 那么联结主义则试图从微观上解决人类的认知功能，以探索认知过程的微观结构

# 样例学习Ⅰ

## 评测指标

- 准确率  
- 速度
  - 构建分类模型的时间（训练速度）
  - 使用分类模型的时间（预测速度）
- 鲁棒性 
  - 模型在处理噪音和缺失值方面的能力
- 可扩展性 ◦
  - 模型用在更大规模的数据集上的能力 
- 可解释性



### 细化评价指标

| 预测值\真实值 | 真   | 假   |
| ------------- | ---- | ---- |
| 真            | a    | b    |
| 假            | c    | d    |

- 细化评价指标
  - Accuracy：$\frac{a+d}{a+b+c+d}$
  - Precision：$\frac{a}{a+b}$
  - Recall：$\frac{a}{a+c}$
  - Miss：$\frac{c}{a+c}$
  - False alarm：$\frac{b}{a+b}$

## K-近邻

### 原理

​	选择样本数据集中前K个最相似的数据（K一般不大于20）；

​	最后，选择K个最近邻中出现次数最多的分类，作为新数据的分类。

### 优点 

- 精度高

- 对异常值不敏感（指离群点对结果影响较小）

- 无数据输入假定 

- 适用数据范围 

  离散型和连续型

### 缺点

-  时间复杂度高（测试集）

-  空间复杂度高（测试集）
-  没有对不同特征的重要性做出区别



## 决策树

### 原理

​	利用归纳算法生成可读的规则和决策树；

​	然后使用决策对新数据进行分析。

### 本质

​	决策树是通过一系列规则 对数据进行分类的过程。

### 优点

- 推理过程**容易理解**，决策推理过程可以表示成If Then形式
- 推理过程完全依赖于属性变量的**取值特点**
- 可自动忽略对目标变量没有贡献的属性变量，也为判断属性变量的**重要性**， 减少变量的数目提供参考。

### 组成部分

1. 决策结点

   每个决策结点代表一个问题或者**决策**， 通常对应待分类对象的**属性**。

2. 分支

   每个分支是一 个**新的决策结点**，或者是**树的叶子**。

3. 叶子

   每个叶结点代表一种可能的分类结果



## 决策树1：CLS

### 步骤

1. 生成一颗**空决策树**和一个**训练样本属性表**

2. 若训练样本集 T 中所有的样本都属于同一类，则生成结点 T ， 并**终止学习**算法
3. 否则根据某种策略从训练样本属性表中选择属性 A 作为测试属性， 生成测试结点A; 若A的取值为v1 , v2 , …, vm，则根据 A 的取值的不同，将 T 划分成 m个子集T1 , T2 , …, Tm
4. 从训练样本属性表中删除属性A
5. 对每个子集递归调用CLS

### 缺陷

选测试属性时没有说怎么选



## 决策树2：ID3

### 原理

​	使用信息增益度来选择测试属性

### 信息量

​	事件$a_i$的**信息量**可以如下度量：
$$
I(a_i)= p(a_i)\log_2\frac{1}{p(a_i)}
$$

​	你对他求导，可以发现在(0,1/2)递增，(1/2,1)递减，这就是确定性!

### 信息熵

​	具有有限个值的离散随机变量$X$的**熵**
$$
H(X)= -\sum_{i = 1}^n p_i \log p_i\\
P(X = x_i)= p_i
$$

- 对数以2为底或以e为底，这时熵的单位分别称作比特(bit)或纳特(nat)
- 熵只依赖于X的分布，与X的取值无关
- 熵越大，随机变量的不确定性越大

### 条件熵

​	表示在己知随机变量$X$ 的条件下随机变量$Y$ 的不确定性，定义为$X$ 给定条件下$Y$ 的条件概率分布的熵对$X$ 的数学期望
$$
H(Y | X)= \sum_{i = 1}^n p_iH(Y|X = x_i)
$$

### 经验熵

​	当熵和条件熵中的概率由数据估计（特别是极大似然估计） 得到时，所对应的熵与条件熵分别称为经验熵（empirical entropy)和经验条件熵（empirical conditional entropy）。

### 信息增益

#### 定义

​	信息增益(Information gain)表示得知特征$X$的信息而使得类$Y$的信息的不确定性减少的程度；

​	—般地，熵H(Y)与条件熵H(Y|X)之差称为互信息 （mutual information) 。

#### 公式

​	特征$A$对训练数据集$D$的信息增益，定义为集合$D$的经验熵$H(D)$与特征$A$给定条件下$D$的经验条件熵$H(D|A)$之差，即 $g(D,A)=H(D)-H(D|A) $。

### 算法

​	决策树节点的属性选择：每次**优先选取信息量最多的属性**，亦即能使熵值变为最小的属性， 以构造一颗熵值下降最快的决策树，到叶子节点处的熵值为0。

### 缺陷

​	ID3趋向于选择分支数较多的属性，而这有可能带来过拟合（噪声被引入）。

​	**改善措施**：1. 验证集

​						2. 信息增益率（C4.5）



## 决策树3：C4.5

$$
g_R(D,A)= \frac{g(D,A)}{H_A(D)}\\
H_A(D)= H(A)= -\sum_{i = 1}^n\frac{|D_i|}{|D|}\log_2\frac{|D_i|}{|D|}
$$



## 决策树4：CART

分类回归树CART(Classification and Regression Trees)

### 回归树

详见ppt

### 分类树

用基尼指数代替信息熵

二分类
$$
\mathbb{Gini}(D) = 1- \sum _{i = 1}^k\left(\frac{|D_k|}{|D|}\right)\\
\mathbb{Gini}(D,A) =\sum_{i = 1}^2\frac{|D_i|}{|D|}\mathbb{Gini}(D_i)
$$


## 剪枝

​	通过极小化决策树**整体的损失函数或代价函数**来实现。
$$
C_{\alpha}(T) = \sum_{i = 1}^{|T|} N_iH_i(T) + \alpha |T|\\
H_i(T) = - \sum_{k}\frac{N_{ik}}{N_i}\log\frac{N_{ik}}{N_i}
$$
​	树$T$的叶节点树是$|T|$，$\alpha$是超参数。

### 1. 预剪枝

​	决策树生成过程+验证集

### 2. 后剪枝

​	完整的决策树+后序遍历+验证集

以上详见lab_2ppt



# 样例学习Ⅱ

## 最小二乘法

### 原理

用线性函数拟合变量间的关系，最小化误差。

### 角度1

最小化目标函数
$$
\begin{align}
Q(w_0,w_1)=\min_{w_0,w_1} \sum_{i=1}^{n}(y_i - w_0 - w_1 x)^2  \tag{目标函数}\\
\frac{\partial Q(w_0,w_1)}{\partial w_0}=-2\sum_{i=1}^{n}(y_i - w_0 - w_1 x)=0\tag{2}\\
\frac{\partial Q(w_0,w_1)}{\partial w_1}-2\sum_{i=1}^{n}x_i(y_i - w_0 - w_1 x)=0\tag{3}\\ \end{align}
$$

### 角度2

一方面使得残差均值为0(2*)；一方面使得残差和x之间的协方差为0（指线性不相关）。
$$
\begin{align}
y = w_0 +w_1x +\epsilon \tag{引入误差}\\
\mathbb{E}(\epsilon)=\frac{1}{n}\sum_{i=1}^{n}(y_i - w_0 - w_1 x)=0 \tag{2*}\\
\mathbb{cov}(\epsilon,x)=\mathbb{E}(\epsilon x)-\mathbb{E}(\epsilon)\mathbb{E}(x)=\mathbb{E}(\epsilon x)=\frac{1}{n}\sum_{i=1}^{n}x_i(y_i - w_0 - w_1 x)=0 \tag{3*}\\
\end{align}
$$


### 缺陷

因为是线性模型，所以预测值可能会超过[0,1]的范围，为此引入sigmoid函数

## 逻辑回归模型

### 预测函数

$$
y = w_0 +\sum^d_{j = 1}w_jx_j  = W^{T}X
$$

### 角度1：odds ratio(机率比)

$$
\log \left(\frac{p}{1-p}\right) =w_0 +\sum^d_{j = 1}w_jx_j
$$

### 角度2：将预测值映射到[0,1]区间

$$
p =\frac{1}{1+ \mathrm{e}^{-w_0 -\sum^d_{j = 1} w_j x_j}}
$$

### 目标函数

因为将p和y作最小二乘法，得到的函数不一定是凸函数；因此使用另外的方法：**最大似然法——找到一个最有可能产生你观察到的数据的参数**
$$
L(W)=\sum_{i=1}^n(y_i\log p_i + (1-y_i)log(1-p_i))
$$

- 化简见ppt上
- 是严格凹函数
- 等价于最小化交叉熵函数



# 人工神经网络Ⅰ

## Perception Learning Algorithm(PLA)

### 适用条件

- 连续数据
- 离散的要转为连续的

### 输出函数

$$
h(\vec x) = sign \left((\sum_{k = 1}^d w_k x_k)-threhold\right) = sign (\tilde W^T \tilde X)
$$

### 代价函数

$$
-y_i \tilde W^T \tilde X_i
$$

- 针对**单个**预测错误的数据
- 考虑了离谱程度

### 算法

1. 初始化$W_{(0)}$，进入循环

2. 找到$W_{(t)}$预测错的原数据$(X_i,y_i)$，更新W：
   $$
   W_{(t+1)} = W_{(t)} + y_iX_i
   $$

3. 直到没有错误

### 几何理解

​	对于增广矩阵$\tilde W$与增广向量$\tilde X$，将整个数据集按$\tilde W^T \tilde X$分为了大于与小于0的两部分，考虑分界线上的两点$\vec A , \vec B$，有$\tilde W^T \vec A = \tilde W^T \vec B = 0$，即$\tilde W^T \vec{AB} = 0$，所以向量权重和线是正交的。
 

如上图，当$y = 1$而$\tilde W^T \tilde X<0$，即向量成钝角时，$\tilde W + y \tilde X$会将其角度减小一点；反之同理；最终成为直角。 

### 收敛性

仅当存在某个超平面。正确划分所有数据时，PLA才会收敛；

另一方面，根据遍历的顺序不同，PLA得出的结果也可能不同。

### 多层

PLA仅仅能适用于单一的label，对于多个label，比如红绿灯是红灯亮还是绿灯亮，若对红灯和绿灯分别使用PLA，那么就可能预测矛盾（一边预测为红灯，一边预测为绿灯），所以我们要考虑一种同时达到两种PLA的效果的结构。



# 人工神经网络Ⅱ

## 背景

PLA无法解决线性不可分的问题;

比如单个神经元（PLA方法可以看成是多个输入X，乘以一个到同个神经元的对应边上的权重W），无法解决**异或**的算法，原因是其结果分布线性不可分；

但要是先将数据结合一下，用符号函数（这里使用了非线性变化），得到中间一层，便可线性可分了；这样的一层就叫它Hidden Layer。

## 解决方法

- 支持向量机，使用核函数
- logistic函数+非线性变化
- 神经网络，使用Hidden layer

## 算法

### 前向传播算法

从前一次迭代获得的权重被用来计算每个神经元的输出值；

先计算前面层的，才能计算后面的。

### 反向传播算法

先更新后面层的权重，再更新前面层的权重（使用到了后面层更新的结果）



## 激活函数

不同于PLA的阈值函数，使用别的激活函数

### Tanh

$$
f(x) = \frac{\mathbb{e} ^{x} -\mathbb{e} ^{-x} }{\mathbb{e} ^{x}+\mathbb{e} ^{-x}} = \frac{\mathbb{e} ^{2x}-1}{\mathbb{e} ^{2x}+1} \\
f'(x) = 1 -f(x)^2
$$

### Sigmoid

$$
f(x) = \frac{1 }{1 +\mathbb{e} ^{x}} \\
f'(x) = f(x)\left(1 -f(x)\right)
$$

## 代价函数

$$
E = \frac{1}{2}\sum_{k \in output\_layer}(O_k - T_k)^2
$$

就是输出值和实际值的欧氏距离

## 梯度的计算

- O~k~：第k个神经元的输出
  $$
  O_j = \frac{1}{1+e^{-I_j}}
  $$

- I~k~：第k个神经元的输入
  $$
  I_j = \sum_{i}w_{ij}O_i + \theta_j
  $$
  其中$i$ 表示k神经元的输入神经元的序号

- Err~k~：第k个神经元的误差（梯度，用于辅助计算）
  $$
  Err_k = - \frac{\partial E}{\partial I_k}
  $$
  对于输出层下标为$k$ 的神经元

$$
Err_k = - \frac{\partial E}{\partial O_k} \frac{\partial O_k}{\partial I_k} = (T_k - O_k) * O_k(1-O_k)=O_k(1-O_k)(T_k - O_k)
$$

​		对于隐藏层下标为$j$ 的神经元
$$
Err_j = - \frac{\partial O_j}{\partial I_j} \frac{\partial E}{\partial O_j}   =\frac{\partial O_j}{\partial I_j} \sum_k - \frac{\partial E}{\partial I_k}\frac{\partial I_k}{\partial O_j}=O_j(1-O_j)\sum_kErr_kw_{jk}
$$

- 权重更新
  $$
  w_{jk} = w_{jk} + \eta Err_kO_j\\
  \theta_k = \theta_k +\eta Err_k\\
  \frac{\partial E}{\partial w_{jk}} = \frac{\partial E}{\partial I_k} \frac{\partial I_k}{\partial w_{jk}} = -Err_kO_j \\
  \frac{\partial E}{\partial \theta_{k}} = \frac{\partial E}{\partial I_k} \frac{\partial I_k}{\partial \theta_{k}} = -Err_k \\
  $$

- https://www.zybuluo.com/hanbingtao/note/476663#an1可作为参考

## 评价

### 缺点

- 训练时间长
- 超参数通常依靠经验确定
- 可解释性差

### 优点

- 高鲁棒性
- 适合于连续值的输入和输出



# 盲目搜索

## 概念

**动作**：表示一个状态到另一个状态

**启发方法**：用于指挥搜索的前进方向

**边界**：还没有被探索，但准备下一步探索的集合

**后继函数**：S(x) = {x状态经过一个动作之后可以到达的状态的集合}，其返回值不仅包括**后继状态**，还要记录获得这个后继状态所经过的**动作**

## 树搜索

```c
TreeSearch(Frontier, Sucessors, Goal? ) 
If Frontier is empty return failure //边界为空就返回失败
Curr = select state from Frontier 	//从当前边界状态中选择一个作为当前要探索的状态
If (Goal?(Curr)) return Curr.		//成功
Frontier’ = (Frontier – {Curr}) U Successors(Curr) 	//失败则将此状态删去，选择后继状态加入边界
return TreeSearch(Frontier’, Successors, Goal?)		//递归搜索
```

## 算法

### 状态选择

- 影响搜索能否找到解（完备性）
- 影响找到解的成本大小（最优性）
- 影响搜索过程所需要的时间和空间资源（时间空间复杂度）

### 选择状态的方式（就是对状态排序的方式）

1. 对边界上的元素进行排序
2. 总是选择第一个元素

### 盲目搜索

- 对于不同的问题，相同的策略
- 策略不考虑问题的领域相关信息

### Ⅰ宽度优先

#### 原理

把当前要扩展的状态的后继状态放到边界的最后

#### 示例
 

#### 性质

完备性：具有；按路径长度搜索，对于长度一定的解，一定会遍历到。

**注意**：当分支数无限时，完备性不具备。

最优性：具有；短的路径会优先遍历。

#### 复杂度

b = 问题中一个状态最大的后继状态个数 

d = 最短解的动作个数

时间复杂度: 
$$
1+ b+ b^2 + . . . + b^d+ b(b^d−1) = O(b^{d+1})
$$


解释： 对于d个动作的树，最优路径的那一层是b^d^个节点；在最差情况下，最优路径在最后一个节点，这时前面b^d^−1个节点的后继节点都加入了边界。

空间复杂度:
$$
b(b^d−1) = O(b^{d+1})
$$

#### 问题

空间复杂度较大

### Ⅱ深度优先

#### 原理

把当前要扩展的状态的后继状态放到边界的最前面

#### 示例
 

#### 性质

完备性：

1. 在状态空间无限的情况下: No （指的是路径无限长的情况）
2. 在状态空间有限，但是存在无限的路径（例如存在回路） 的情况下: No
3. 在状态空间有限，且对重复路径进行剪枝的情况下：Yes

最优性：不具有；没有优先找短的路径

#### 复杂度

m是**遍历过程**中**最长路径的长度**

时间复杂度：1+ b+ b^2^ + . . . + b^m^ = O(b^m^) 

注意：m和d没关系，所以当m远远大于d时，时间效率会很差；

空间复杂度：O(bm)

解释：每个时刻边界只包含当前探索的最深的节点，以及这条路径上的点的未扩展过的兄弟节点（b-1个）

#### 问题

既没有最优性也没完备性；但是空间复杂度较低；时间复杂度可能会很高。

### Ⅲ一致代价

#### 原理

优先扩展成本最低的那条路径

（当每个动作成本一样，与宽度优先一样）

#### 性质

最优性：具备；优先扩展成本较低的路径。

完备性：具备；按成本序遍历路径，一定会找到某个成本的路径。

#### 复杂度

假设每个动作的成本 ≥ s > 0；最优解的成本为C\*；则最优路径的最多步数为C*/s。

套用宽度优先，得到时间复杂度和空间复杂度都是O(b^C*/s+1^)

#### 问题

空间复杂度过大

### Ⅳ深度受限

#### 原理

预先限制了搜索深度的深度搜索

#### 示例
 

#### 性质

完备性：NO；当解路径的长度 ≤L 时，才能找到解。

最优性：NO；因为深度的内核。

#### 复杂度

套用深度；m = L；

时间复杂度: O(b^L^) 

空间复杂度: O(bL)

#### 评价

因为是"深度"，所以避免了空间复杂度较高的问题；因为“受限”，所以无限长度的路径不会导致深度优先搜索无法停止的问题。

### Ⅴ迭代加深

#### 原理

迭代地增加深度限制L，对于每个L都进行深度受限搜索。

#### 算法伪代码

1. 一开始设置深度限制为L = 0，我们迭代地增加深度限制，对于每个深度限制都进行深度受限搜索
2. 如果找到解，或者深度受限搜索没有节点可以扩展的时候可以停止当前迭代，并提高深度限制L
3. 如果深度限制不能再提高，仍然没有找到解，那么说明已经搜索所有路径，因此这个搜索不存在解

#### 示例 

注意：每次都是从头开始。

#### 性质

完备性：YES；对于一定长度的最优路径，对应的深度受限搜索一定能找到这个路径。

最优性：YES（在每个动作的成本一致的情况下）；对于一定长度的最优路径，比他长的会在后面找。

#### 复杂度

时间复杂度：第一层节点访问了d+1次，最后一层节点访问了1次
$$
(d+1)b^0+db+......+b^d = O(b^d)
$$
空间复杂度：
$$
O(bd)
$$


#### 评价

为了解决**深度优先搜索**（时间复杂度可能太高，具备完备性）和**宽度优先搜索**（空间复杂度高）存在的问题。

迭代加深当然比深度优先搜索好，但是也比宽度优先好：不用扩展深度限制上的节点，而宽度优先搜索需要扩展直到目标节点（就是宽度优先搜索会比迭代加深多扩展一层节点）。

### Ⅵ双向搜索

#### 原理

同时进行**从初始状态向前的搜索**和从目标节点向后搜索，在两个搜索在中间相遇时停止搜索。

#### 示例 

#### 性质与复杂度

当均使用宽度优先搜索时：

- 完备性：具备

- 最优性：具备（在每条边/每个动作成本一致的情况下）

- 时间和空间复杂度均为：（看成两个搜索到最优路径中点即停）
  $$
  O(b^{d/2})
  $$

## 总结
 

## 两种检测方法

### 路径检测

**单独检测每条**路径上是否出现**重复**节点

### 环检测

当扩展某个节点时，确保其不等于之前任何扩展过的节点。

- 不能用于深度优先搜索
  - 因为会产生较高的空间复杂度，与深度优先搜索的特性——较低的空间复杂度相抵，方法没效果了。
  - 可以用于宽度优先搜索
- 对于一致代价搜索，使用环检测后仍可以找到最优解。（第一次到达某个节点已是最优，所以环检测剔除的节点不可能在一条更短的路径上）
  - 但是对于**启发式搜索**，这个性质不一定会成立。



# 启发式搜索

## 背景

盲目搜索没有考虑当前节点到目标节点的成本，而如果有这些额外知识，我们可能可以更好的确定边界节点的搜索顺序。

### 启发函数

- 记作h(n)

- 用于估计节点n到目标节点的成本

- 对于目标节点，h(n)=0

- 启发式函数随着问题领域的不同而不同

- 例子：地图中可以用当前节点到目标的欧氏距离作为启发式函数

- 搜索策略：

  1. 贪心最佳优先搜索（Greedy BFS）

     - 仅仅利用h(n)的排序结果进行搜索，可能选择那些里目标节点近但是离初始节点远的节点。

     - 既不完备也不最优。

  2. A*搜索

     - g(n)是初始节点到达n节点的路径成本。
     - f(n) = g(n)+h(n)，所以f(n)表示从初始节点到达目标节点的路径成本的估计值



# 博弈树

$$
\min \to \beta , min节点取值上界\\
\max \to \alpha,max节点取值下界
$$

从书中例子看似乎就只是一一对应。

并且α-β剪枝算法只要是祖先和当前节点满足α>β就可剪枝。



```pseudocode
function ALPHA-BETA-SEARCH(state) returns an action
 v ← MAX-VALUE(state, −∞, +∞)
 return the action in ACTIONS(state) with value v
 
 function MAX-VALUE(state, α, β) returns a utility value
 if TERMINAL-TEST(state) then return UTILITY(state)
 v ← −∞
 for each a in ACTIONS(state) do
   v ← MAX(v, MIN-VALUE(RESULT(state, a), α, β))
   if v ≥ β then return v
   α ← MAX(α, v)
 return v
 
 function MIN-VALUE(state, α, β) returns a utility value
 if TERMINAL-TEST(state) then return UTILITY(state)
 v ← +∞
 for each a in ACTIONS(state) do
   v ← MIN(v, MAX-VALUE(RESULT(state, a), α, β))
   if v ≤ α then return v
   β ← MIN(β, v)
 return v
 
```

